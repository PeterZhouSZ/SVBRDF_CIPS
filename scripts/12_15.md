

a. fed patterns to top + add channel conv + resize 256:

> python -m torch.distributed.launch --nproc_per_node=4 --master_port=1234 train.py --n_sample=2 --batch=2 --Generator=CIPSskip --output_dir=pat8top_chconv_resize --img2dis --num_workers=4 ./Data/Bricks_pat2/512 --img_c 5 --coords_size 256 --size 256 --crop_size 256 --N_emb 10 --latent 64 --fc_dim 64 --emb_pat blur --in_pat top --in_pat_c 8 --resize_data --add_chconv


b. fed patterns to top + add pattern embeds:

> python -m torch.distributed.launch --nproc_per_node=4 --master_port=1234 train.py --n_sample=2 --batch=2 --Generator=CIPSskip --output_dir=embpat8_top --img2dis --num_workers=4 ./Data/Bricks_pat2/512 --img_c 5 --coords_size 512 --size 256 --crop_size 256 --N_emb 10 --latent 64 --fc_dim 64 --emb_pat emb_blur --in_pat top --in_pat_c 8

c. fed patterns to top + add pattern embeds + resize 256:

> python -m torch.distributed.launch --nproc_per_node=4 --master_port=1234 train.py --n_sample=2 --batch=2 --Generator=CIPSskip --output_dir=embpat8_top --img2dis --num_workers=4 ./Data/Bricks_pat2/512 --img_c 5 --coords_size 256 --size 256 --crop_size 256 --N_emb 10 --latent 64 --fc_dim 64 --emb_pat emb_blur --in_pat top --in_pat_c 8 --resize_data
